{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Winning Jeopardy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "jeopardy = pd.read_csv(\"jeopardy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy.columns = jeopardy.columns.str.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ShowNumber', 'AirDate', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalizer(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"[^A-Za-z0-9\\s]\",\"\",text)\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy['clean_question'] = jeopardy[\"Question\"].apply(normalizer)\n",
    "jeopardy['clean_answer'] = jeopardy[\"Answer\"].apply(normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_values(text):\n",
    "    text = re.sub(\"[^A-Za-z0-9\\s]\", \"\", text)\n",
    "    try:\n",
    "        text = int(text)\n",
    "    except Exception:\n",
    "        text = 0\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy[\"clean_value\"] = jeopardy[\"Value\"].apply(normalize_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2004-12-31\n",
       "1       2004-12-31\n",
       "2       2004-12-31\n",
       "3       2004-12-31\n",
       "4       2004-12-31\n",
       "5       2004-12-31\n",
       "6       2004-12-31\n",
       "7       2004-12-31\n",
       "8       2004-12-31\n",
       "9       2004-12-31\n",
       "10      2004-12-31\n",
       "11      2004-12-31\n",
       "12      2004-12-31\n",
       "13      2004-12-31\n",
       "14      2004-12-31\n",
       "15      2004-12-31\n",
       "16      2004-12-31\n",
       "17      2004-12-31\n",
       "18      2004-12-31\n",
       "19      2004-12-31\n",
       "20      2004-12-31\n",
       "21      2004-12-31\n",
       "22      2004-12-31\n",
       "23      2004-12-31\n",
       "24      2004-12-31\n",
       "25      2004-12-31\n",
       "26      2004-12-31\n",
       "27      2004-12-31\n",
       "28      2004-12-31\n",
       "29      2004-12-31\n",
       "           ...    \n",
       "19969   2009-05-14\n",
       "19970   2009-05-14\n",
       "19971   2009-05-14\n",
       "19972   2009-05-14\n",
       "19973   2009-05-14\n",
       "19974   2009-05-14\n",
       "19975   2009-05-14\n",
       "19976   2009-05-14\n",
       "19977   2009-05-14\n",
       "19978   2009-05-14\n",
       "19979   2009-05-14\n",
       "19980   2009-05-14\n",
       "19981   2009-05-14\n",
       "19982   2009-05-14\n",
       "19983   2009-05-14\n",
       "19984   2009-05-14\n",
       "19985   2009-05-14\n",
       "19986   2009-05-14\n",
       "19987   2009-05-14\n",
       "19988   2000-03-14\n",
       "19989   2000-03-14\n",
       "19990   2000-03-14\n",
       "19991   2000-03-14\n",
       "19992   2000-03-14\n",
       "19993   2000-03-14\n",
       "19994   2000-03-14\n",
       "19995   2000-03-14\n",
       "19996   2000-03-14\n",
       "19997   2000-03-14\n",
       "19998   2000-03-14\n",
       "Name: AirDate, Length: 19999, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(jeopardy[\"AirDate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def splitter(row):\n",
    "    #split every word in columns\n",
    "    split_answer = row[\"clean_answer\"].split()\n",
    "    split_question = row[\"clean_question\"].split()\n",
    "    \n",
    "    match_count = 0 \n",
    "    #remove \"the\" because it doesn't have any meaningful use\n",
    "    if \"the\" in split_answer: \n",
    "        split_answer.remove(\"the\")\n",
    "    if len(split_answer) == 0:\n",
    "        return\n",
    "    #Count how many times terms in clean_answer occur in clean_question\n",
    "    for item in split_answer:\n",
    "        if item in split_question:\n",
    "            match_count += 1 \n",
    "            \n",
    "    return match_count / len(split_answer)\n",
    "\n",
    "jeopardy[\"answer_in_question\"] = jeopardy.apply(splitter, axis = 1)\n",
    "\n",
    "ans_in_ques_mean = jeopardy[\"answer_in_question\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05900491564307945"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_in_ques_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recycled questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "\n",
    "jeopardy[\"AirDate\"] = jeopardy[\"AirDate\"].sort_values(ascending = False)\n",
    "\n",
    "for i, row in jeopardy.iterrows():\n",
    "    split_question = row[\"clean_question\"].split(\" \")\n",
    "    split_question = [x for x in split_question if len(x) > 5]\n",
    "    \n",
    "    match_count = 0 \n",
    "    \n",
    "    for word in split_question: \n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "    for word in split_question: \n",
    "        terms_used.add(word)\n",
    "        \n",
    "    if len(split_question) > 0:\n",
    "        match_count /= len(split_question)\n",
    "    question_overlap.append(match_count)\n",
    "    \n",
    "jeopardy[\"question_overlap\"] = question_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All rows were filtered, we keep only rows which have six or more characters in words to filter out from \"the\", \"than\", etc. which are commonly used, but don't tell you about a lot about a question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low value vs high value questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def determine_value(row):\n",
    "    value = 0\n",
    "    if int(row[\"clean_value\"]) > 800:\n",
    "        value = 1\n",
    "    else: \n",
    "        value = 0\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy[\"high_value\"] = jeopardy.apply(determine_value, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_usage(term):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for i, row in jeopardy.iterrows():\n",
    "        if term in row[\"clean_question\"].split(\" \"):\n",
    "            if row[\"high_value\"] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2),\n",
       " (3, 6),\n",
       " (2, 2),\n",
       " (0, 1),\n",
       " (3, 4),\n",
       " (1, 2),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (1, 10)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import choice\n",
    "\n",
    "terms_used_list = list(terms_used)\n",
    "comparison_terms = [choice(terms_used_list) for _ in range(10)]\n",
    "\n",
    "observed_expected = []\n",
    "\n",
    "for term in comparison_terms:\n",
    "    observed_expected.append(count_usage(term))\n",
    "\n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the chi-squared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "high_value_count = jeopardy[jeopardy[\"high_value\"] == 1].shape[0]\n",
    "low_value_count = jeopardy[jeopardy[\"high_value\"] == 0].shape[0]\n",
    "\n",
    "chi_squared = []\n",
    "\n",
    "for obs in observed_expected:\n",
    "    total = sum(obs)\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    \n",
    "    high_value_exp = total_prop * high_value_count\n",
    "    low_value_exp = total_prop * low_value_count\n",
    "    \n",
    "    observed = np.array([obs[0],obs[1]])\n",
    "    expected = np.array([high_value_exp, low_value_exp])\n",
    "    chi_squared.append(chisquare(observed,expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=0.03188116723440362, pvalue=0.8582887163235293),\n",
       " Power_divergenceResult(statistic=0.09564350170321084, pvalue=0.75712159875701),\n",
       " Power_divergenceResult(statistic=0.889754963322559, pvalue=0.3455437191483468),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.6887906561130311, pvalue=0.4065760282166111),\n",
       " Power_divergenceResult(statistic=0.03188116723440362, pvalue=0.8582887163235293),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=2.0621887936258245, pvalue=0.15099314777510028)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the terms had a significant difference in usage between high value and low value rows. Additionally, the frequencies were all lower than 5, so the chi-squared test isn't as valid. It would be better to run this test with only terms that have higher frequencies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
